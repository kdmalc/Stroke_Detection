{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cb7c57",
   "metadata": {},
   "source": [
    "> __Purpose__: To run various regression ML algorithms, find best performers, and further optimize by tuning the hyperparameters of successful models.\n",
    "<br>\n",
    "\n",
    "> To Do: \n",
    " -  Go through and read assumptions of each model, for which should be most applicable\n",
    " - Grid/random search for hyper-parameter tuning?\n",
    " - Functionalize current code so it can easily scale up for more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0cb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, tree, preprocessing, metrics, linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# PLT Defaults\n",
    "title_font_size = 30\n",
    "label_font_size = 20\n",
    "\n",
    "plt.rc('font', size=title_font_size) #controls default text size\n",
    "plt.rc('axes', titlesize=title_font_size) #fontsize of the title\n",
    "plt.rc('axes', labelsize=label_font_size) #fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=label_font_size) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=label_font_size) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=label_font_size) #fontsize of the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f4c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(my_mat_files_lst, my_labels_lst, data_folders=['Data'], label_folders=['Labels']):\n",
    "    '''\n",
    "    Purpose:\n",
    "    \n",
    "    Inputs:\n",
    "        my_mat_files_lst:\n",
    "            List of .mat file names (as strings) containing the desired data\n",
    "        my_labels_lst:\n",
    "            List of .npy file names (as strings) containing the corresponding labels to the above\n",
    "        data_folders:\n",
    "            Folders containing the data files.  If just in the /Data folder you can just ignore this \n",
    "            and it'll automatically take care of the file paths\n",
    "        label_folders:\n",
    "            Folders containing the label files.  If just in the /Labels folder you can just ignore this \n",
    "            and it'll automatically take care of the file paths\n",
    "    Outputs:\n",
    "        rict_df:\n",
    "            Pandas dataframe of the r_ICT data.  It is plotted below\n",
    "        reg_labels_npy:\n",
    "            Numpy array containing the corresponding timestamps at which the stroke occurred.\n",
    "    '''\n",
    "    \n",
    "    num_mats = len(my_mat_files_lst)\n",
    "    # Number of vessels that each .mat file contains\n",
    "    num_vessels_lst = [0] * num_mats\n",
    "    # List containing each said .mat file\n",
    "    mat_data_lst = [0] * num_mats\n",
    "    # List containing all the loaded in label data\n",
    "    labels_lst = [0] * num_mats\n",
    "    # DATA TO BE EXTRACTED FROM .MAT FILES\n",
    "    m_rICT = [0] * num_mats\n",
    "    t = [0] * num_mats\n",
    "    # Data structures to be returned, e.g.the data and labels\n",
    "    rict_df = pd.DataFrame()\n",
    "    reg_labels_npy = np.array([])\n",
    "    \n",
    "    # INPUT LIST\n",
    "    for i, my_mat in enumerate(my_mat_files_lst):\n",
    "        if len(data_folders)!=1:\n",
    "            print(\"This data functionality isn't supported yet... come ctrl+f this line and write it\")\n",
    "        else:\n",
    "            # You should be loading in the reg only data here\n",
    "            mat_data_lst[i] = loadmat(os.path.join(data_folders[0], my_mat))\n",
    "            #np.load(os.path.join(data_folders[0], my_mat))\n",
    "            #np.load is broken with paths on Windows lol\n",
    "        \n",
    "    # LABELS\n",
    "    for i, my_labels in enumerate(my_labels_lst):\n",
    "        if len(label_folders)!=1:\n",
    "            print(\"This label functionality isn't supported yet... come ctrl+f this line and write it\")\n",
    "        else:\n",
    "            # You should be loading in the reg only data here\n",
    "            labels_lst[i] = np.load(os.path.join(label_folders[0], my_labels))\n",
    "    # This returns an array of which vessels were stroked (e.g. [1, 4])... I don't think I used this\n",
    "    #np.nonzero(y_train_reg95)[0]\n",
    "    \n",
    "    # Find max vector length (e.g. rICT with most samples)... there's probably a better way to do this \n",
    "    running_max = 0\n",
    "    for i, mat in enumerate(mat_data_lst):\n",
    "        # Keep track of how many vessels the given .mat has... this is important later\n",
    "        num_vessels_lst[i] = mat['names'].shape[1]\n",
    "        \n",
    "        m_rICT[i] = mat['rICT']\n",
    "        # Need to find what the longest rICT vector is\n",
    "        if m_rICT[i].shape[0] > running_max:\n",
    "            running_max = m_rICT[i].shape[0]\n",
    "        m_t = mat['t']\n",
    "        t[i] = m_t.reshape((m_t.shape[1]))\n",
    "        \n",
    "    ## NOW CREATE THE RICT_DF\n",
    "    # Create the rict_df of input, and the labels_df \n",
    "    for i in range(len(num_vessels_lst)):\n",
    "        # First, zero pad to reach max vector length\n",
    "        if running_max - m_rICT[i].shape[0] > 0:\n",
    "            zp_mat = np.zeros(((running_max - m_rICT[i].shape[0]), num_vessels_lst[i]))\n",
    "            # Instead of just zero padding, try setting the last value to just be constant (the last recorded value)\n",
    "            for j in range(num_vessels_lst[i]):\n",
    "                zp_mat[:, j] += m_rICT[i][-1][j]\n",
    "            zp_rict = np.concatenate((m_rICT[i], zp_mat))\n",
    "        else:\n",
    "            zp_rict = m_rICT[i]\n",
    "\n",
    "        # Now safely append to dataframe\n",
    "        rict_df = pd.concat((rict_df, pd.DataFrame(np.transpose(zp_rict)))) #, axis=1\n",
    "        # Labels\n",
    "        reg_labels_npy = np.concatenate((reg_labels_npy, labels_lst[i]))\n",
    "\n",
    "        print(f\"{i}: delta t is {(t[i][25] - t[i][0])/25}\")\n",
    "\n",
    "    rict_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return rict_df, reg_labels_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f46fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: delta t is 0.14110399999998663\n",
      "1: delta t is 0.00736\n"
     ]
    }
   ],
   "source": [
    "rict_df, reg_labels_npy = load_data(['data_94b.mat', 'data_95q.mat'], ['94b_reg.npy', '95_reg.npy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514b5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 4000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.061179</td>\n",
       "      <td>1.036253</td>\n",
       "      <td>1.073106</td>\n",
       "      <td>0.970642</td>\n",
       "      <td>0.957931</td>\n",
       "      <td>0.929883</td>\n",
       "      <td>0.968243</td>\n",
       "      <td>0.960815</td>\n",
       "      <td>0.965519</td>\n",
       "      <td>1.005626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "      <td>0.557441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.017361</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>1.013525</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.932092</td>\n",
       "      <td>0.962371</td>\n",
       "      <td>0.985138</td>\n",
       "      <td>0.994388</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>1.001761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114077</td>\n",
       "      <td>1.059771</td>\n",
       "      <td>1.078420</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.951927</td>\n",
       "      <td>0.979590</td>\n",
       "      <td>1.005449</td>\n",
       "      <td>1.010853</td>\n",
       "      <td>1.028106</td>\n",
       "      <td>1.053987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.096296</td>\n",
       "      <td>1.021505</td>\n",
       "      <td>1.078318</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.961240</td>\n",
       "      <td>0.990814</td>\n",
       "      <td>0.992204</td>\n",
       "      <td>1.000505</td>\n",
       "      <td>1.047153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.147843</td>\n",
       "      <td>1.105764</td>\n",
       "      <td>1.058356</td>\n",
       "      <td>1.011027</td>\n",
       "      <td>0.935990</td>\n",
       "      <td>0.957186</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>0.988637</td>\n",
       "      <td>0.962370</td>\n",
       "      <td>1.026500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "      <td>0.547024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  1.061179  1.036253  1.073106  0.970642  0.957931  0.929883  0.968243   \n",
       "1  1.017361  0.968635  1.013525  0.959467  0.932092  0.962371  0.985138   \n",
       "2  1.114077  1.059771  1.078420  0.993976  0.951927  0.979590  1.005449   \n",
       "3  1.096296  1.021505  1.078318  0.988432  0.953285  0.961240  0.990814   \n",
       "4  1.147843  1.105764  1.058356  1.011027  0.935990  0.957186  0.957919   \n",
       "\n",
       "       7         8         9     ...      3990      3991      3992      3993  \\\n",
       "0  0.960815  0.965519  1.005626  ...  0.557441  0.557441  0.557441  0.557441   \n",
       "1  0.994388  0.998228  1.001761  ...  0.625993  0.625993  0.625993  0.625993   \n",
       "2  1.010853  1.028106  1.053987  ...  0.633713  0.633713  0.633713  0.633713   \n",
       "3  0.992204  1.000505  1.047153  ...  0.330870  0.330870  0.330870  0.330870   \n",
       "4  0.988637  0.962370  1.026500  ...  0.547024  0.547024  0.547024  0.547024   \n",
       "\n",
       "       3994      3995      3996      3997      3998      3999  \n",
       "0  0.557441  0.557441  0.557441  0.557441  0.557441  0.557441  \n",
       "1  0.625993  0.625993  0.625993  0.625993  0.625993  0.625993  \n",
       "2  0.633713  0.633713  0.633713  0.633713  0.633713  0.633713  \n",
       "3  0.330870  0.330870  0.330870  0.330870  0.330870  0.330870  \n",
       "4  0.547024  0.547024  0.547024  0.547024  0.547024  0.547024  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rict_df.shape)\n",
    "rict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f81ee67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0., 343.,   0.,   0.,   0.,   0., 263.,   0.,   0.,\n",
       "       263.,   0.,   0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_labels_npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad506b5",
   "metadata": {},
   "source": [
    "## Make training df\n",
    "> Code form here forward is not functionalized..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(rict_df, reg_labels_npy, rng_seed=2):\n",
    "    ''''''\n",
    "    \n",
    "    x_train = rict_df.copy(deep=True)\n",
    "    y_train_reg = reg_labels_npy\n",
    "\n",
    "    ## TRAIN / TEST\n",
    "    # Stratify might be good to ensure that all classes are represented, I'm not sure if it'll do that by default\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        x_train, y_train_reg, test_size=0.3, random_state=rng_seed)\n",
    "\n",
    "    ## TRAIN / VAL\n",
    "    # Might not use... easier to just use cross validation I think\n",
    "    X_train_pv, X_val_only, y_train_pv, X_val_only = train_test_split(\n",
    "        X_train, y_train, test_size=0.3, random_state=rng_seed)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, [X_train_pv, X_val_only, y_train_pv, X_val_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1513a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of decimal points\n",
    "num_dps = 3\n",
    "\n",
    "# Result logs\n",
    "my_metrics_cols = ['Algorithm', 'One Off r2', 'CV r2', 'K Folds']\n",
    "res_df = pd.DataFrame(columns=my_metrics_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7daf783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 4000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.096296</td>\n",
       "      <td>1.021505</td>\n",
       "      <td>1.078318</td>\n",
       "      <td>0.988432</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.961240</td>\n",
       "      <td>0.990814</td>\n",
       "      <td>0.992204</td>\n",
       "      <td>1.000505</td>\n",
       "      <td>1.047153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "      <td>0.330870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.017361</td>\n",
       "      <td>0.968635</td>\n",
       "      <td>1.013525</td>\n",
       "      <td>0.959467</td>\n",
       "      <td>0.932092</td>\n",
       "      <td>0.962371</td>\n",
       "      <td>0.985138</td>\n",
       "      <td>0.994388</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>1.001761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "      <td>0.625993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.066983</td>\n",
       "      <td>1.065764</td>\n",
       "      <td>1.011728</td>\n",
       "      <td>1.043583</td>\n",
       "      <td>1.052560</td>\n",
       "      <td>1.044963</td>\n",
       "      <td>1.002310</td>\n",
       "      <td>1.001666</td>\n",
       "      <td>1.008263</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887042</td>\n",
       "      <td>0.858210</td>\n",
       "      <td>0.826764</td>\n",
       "      <td>0.857343</td>\n",
       "      <td>0.858843</td>\n",
       "      <td>0.909248</td>\n",
       "      <td>0.869098</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.932869</td>\n",
       "      <td>0.956156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.104496</td>\n",
       "      <td>1.070832</td>\n",
       "      <td>1.021953</td>\n",
       "      <td>1.018994</td>\n",
       "      <td>1.026853</td>\n",
       "      <td>1.079162</td>\n",
       "      <td>1.001277</td>\n",
       "      <td>0.988058</td>\n",
       "      <td>1.010397</td>\n",
       "      <td>1.037769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840213</td>\n",
       "      <td>0.859675</td>\n",
       "      <td>0.777621</td>\n",
       "      <td>0.779733</td>\n",
       "      <td>0.846882</td>\n",
       "      <td>0.876658</td>\n",
       "      <td>0.811055</td>\n",
       "      <td>0.747194</td>\n",
       "      <td>0.825856</td>\n",
       "      <td>0.863287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.050900</td>\n",
       "      <td>1.073872</td>\n",
       "      <td>1.027361</td>\n",
       "      <td>1.035323</td>\n",
       "      <td>1.069433</td>\n",
       "      <td>1.141084</td>\n",
       "      <td>1.038832</td>\n",
       "      <td>1.040030</td>\n",
       "      <td>1.062012</td>\n",
       "      <td>1.043047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747488</td>\n",
       "      <td>0.807798</td>\n",
       "      <td>0.760712</td>\n",
       "      <td>0.765627</td>\n",
       "      <td>0.789382</td>\n",
       "      <td>0.817645</td>\n",
       "      <td>0.783503</td>\n",
       "      <td>0.759102</td>\n",
       "      <td>0.805076</td>\n",
       "      <td>0.811686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.114077</td>\n",
       "      <td>1.059771</td>\n",
       "      <td>1.078420</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.951927</td>\n",
       "      <td>0.979590</td>\n",
       "      <td>1.005449</td>\n",
       "      <td>1.010853</td>\n",
       "      <td>1.028106</td>\n",
       "      <td>1.053987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "      <td>0.633713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.109880</td>\n",
       "      <td>1.038855</td>\n",
       "      <td>1.069371</td>\n",
       "      <td>0.961510</td>\n",
       "      <td>0.945293</td>\n",
       "      <td>0.981855</td>\n",
       "      <td>0.987191</td>\n",
       "      <td>0.965419</td>\n",
       "      <td>1.008696</td>\n",
       "      <td>1.044981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.608597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.020680</td>\n",
       "      <td>1.043329</td>\n",
       "      <td>1.014699</td>\n",
       "      <td>1.035490</td>\n",
       "      <td>1.061703</td>\n",
       "      <td>1.147812</td>\n",
       "      <td>1.021042</td>\n",
       "      <td>1.026305</td>\n",
       "      <td>1.038700</td>\n",
       "      <td>1.079479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702295</td>\n",
       "      <td>0.717989</td>\n",
       "      <td>0.666838</td>\n",
       "      <td>0.687880</td>\n",
       "      <td>0.653884</td>\n",
       "      <td>0.722928</td>\n",
       "      <td>0.716428</td>\n",
       "      <td>0.648219</td>\n",
       "      <td>0.697895</td>\n",
       "      <td>0.755185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.065481</td>\n",
       "      <td>1.069529</td>\n",
       "      <td>1.009902</td>\n",
       "      <td>0.991405</td>\n",
       "      <td>1.005429</td>\n",
       "      <td>1.054504</td>\n",
       "      <td>0.979722</td>\n",
       "      <td>0.973506</td>\n",
       "      <td>1.052902</td>\n",
       "      <td>1.028863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383608</td>\n",
       "      <td>0.386855</td>\n",
       "      <td>0.342665</td>\n",
       "      <td>0.360486</td>\n",
       "      <td>0.367121</td>\n",
       "      <td>0.382111</td>\n",
       "      <td>0.373386</td>\n",
       "      <td>0.338323</td>\n",
       "      <td>0.364161</td>\n",
       "      <td>0.383121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "3   1.096296  1.021505  1.078318  0.988432  0.953285  0.961240  0.990814   \n",
       "1   1.017361  0.968635  1.013525  0.959467  0.932092  0.962371  0.985138   \n",
       "10  1.066983  1.065764  1.011728  1.043583  1.052560  1.044963  1.002310   \n",
       "7   1.104496  1.070832  1.021953  1.018994  1.026853  1.079162  1.001277   \n",
       "12  1.050900  1.073872  1.027361  1.035323  1.069433  1.141084  1.038832   \n",
       "2   1.114077  1.059771  1.078420  0.993976  0.951927  0.979590  1.005449   \n",
       "6   1.109880  1.038855  1.069371  0.961510  0.945293  0.981855  0.987191   \n",
       "13  1.020680  1.043329  1.014699  1.035490  1.061703  1.147812  1.021042   \n",
       "8   1.065481  1.069529  1.009902  0.991405  1.005429  1.054504  0.979722   \n",
       "\n",
       "        7         8         9     ...      3990      3991      3992      3993  \\\n",
       "3   0.992204  1.000505  1.047153  ...  0.330870  0.330870  0.330870  0.330870   \n",
       "1   0.994388  0.998228  1.001761  ...  0.625993  0.625993  0.625993  0.625993   \n",
       "10  1.001666  1.008263  0.997008  ...  0.887042  0.858210  0.826764  0.857343   \n",
       "7   0.988058  1.010397  1.037769  ...  0.840213  0.859675  0.777621  0.779733   \n",
       "12  1.040030  1.062012  1.043047  ...  0.747488  0.807798  0.760712  0.765627   \n",
       "2   1.010853  1.028106  1.053987  ...  0.633713  0.633713  0.633713  0.633713   \n",
       "6   0.965419  1.008696  1.044981  ...  0.608597  0.608597  0.608597  0.608597   \n",
       "13  1.026305  1.038700  1.079479  ...  0.702295  0.717989  0.666838  0.687880   \n",
       "8   0.973506  1.052902  1.028863  ...  0.383608  0.386855  0.342665  0.360486   \n",
       "\n",
       "        3994      3995      3996      3997      3998      3999  \n",
       "3   0.330870  0.330870  0.330870  0.330870  0.330870  0.330870  \n",
       "1   0.625993  0.625993  0.625993  0.625993  0.625993  0.625993  \n",
       "10  0.858843  0.909248  0.869098  0.841970  0.932869  0.956156  \n",
       "7   0.846882  0.876658  0.811055  0.747194  0.825856  0.863287  \n",
       "12  0.789382  0.817645  0.783503  0.759102  0.805076  0.811686  \n",
       "2   0.633713  0.633713  0.633713  0.633713  0.633713  0.633713  \n",
       "6   0.608597  0.608597  0.608597  0.608597  0.608597  0.608597  \n",
       "13  0.653884  0.722928  0.716428  0.648219  0.697895  0.755185  \n",
       "8   0.367121  0.382111  0.373386  0.338323  0.364161  0.383121  \n",
       "\n",
       "[9 rows x 4000 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, val_splits_lst = prepare_for_training(rict_df, reg_labels_npy)\n",
    "\n",
    "# Note the row indexes are crazy because of the train_test_split recombination, I believe.  It should be fine.\n",
    "print(X_train.shape)\n",
    "X_train.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d3c12",
   "metadata": {},
   "source": [
    "## ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf879f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ml_algo(algo, X_train, y_train, cv, verbose=False, num_decimals=3, testing=False):\n",
    "    '''Runs given algorithm and returns the accuracy metrics'''\n",
    "    \n",
    "    model = algo.fit(X_train, y_train)\n",
    "    \n",
    "    # Notice that this is tested on the data it just trained on...\n",
    "    #[WHEN CALLED ON REGRESSORS, IT AUTOMATICALLY RETURNS R2. ON CLASS IT RETURNS ACC]\n",
    "    r2 = round(model.score(X_train, y_train) * 100, 3)\n",
    "    \n",
    "    # Cross Validation - this fixes that issue of validating on the data that the model was trained on\n",
    "    train_pred = model_selection.cross_val_predict(algo, \n",
    "                                                  X_train, \n",
    "                                                  y_train, \n",
    "                                                  cv=cv, \n",
    "                                                  n_jobs=-1)\n",
    "    # Cross-validation metric [ACCURACY IS ONLY FOR CLASSIFICATION!!!]\n",
    "    #mse_cv = round(metrics.mean_squared_error(y_train, train_pred) * 100, num_decimals)\n",
    "    r2_cv = round(metrics.r2_score(y_train, train_pred) * 100, num_decimals)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Training predictions:\")\n",
    "        print(train_pred)\n",
    "        print(\"Ground Truth:\")\n",
    "        print(y_train)\n",
    "        print(f\"One Off r2: {r2}\")\n",
    "        print(f\"CV r2: {r2_cv}\")\n",
    "    \n",
    "    if testing:\n",
    "        return train_pred, r2, r2_cv, model\n",
    "    \n",
    "    return train_pred, r2, r2_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2023a4a",
   "metadata": {},
   "source": [
    "## Set the number of k-folds for cross validation\n",
    "> Minimum is 1 (I think) and the max is simply the number of samples you have (e.g. number of rows). You could tune it to find what number of k folds has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f758207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fab301",
   "metadata": {},
   "source": [
    "Some things you could do, not sure if it's worth it / beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ad0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scalerX = StandardScaler().fit(X_train)\n",
    "#scalery = StandardScaler().fit(y_train)\n",
    "\n",
    "#X_train = scalerX.transform(X_train)\n",
    "#y_train = scalery.transform(y_train)\n",
    "#X_test = scalerX.transform(X_test)\n",
    "#y_test = scalery.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd7ad6",
   "metadata": {},
   "source": [
    "## Regression\n",
    "> https://medium.com/analytics-vidhya/5-regression-algorithms-you-need-to-know-theory-implementation-37993382122d\n",
    "1. Linear Regression\n",
    "2. Neural Network Regression --> Use a linear activation function on the last layer\n",
    "3. Decision Tree Regression\n",
    "4. LASSO Regression --> Good for data that shows heavy multicollinearity (heavy correlation of features with each other)\n",
    "5. Rdige Regression --> Also good for datasets that have an abundant amount of featuesr which are not indepdent (collinearity) from one another\n",
    "6. ElasticNet Regression\n",
    "> https://www.jigsawacademy.com/popular-regression-algorithms-ml/\n",
    "1. Random Forest\n",
    "2. SVM\n",
    "3. Gaussian Regression\n",
    "4. Polynomial Regression\n",
    "> https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "- Metrics we care about ^^\n",
    "> https://towardsdatascience.com/cyclical-features-encoding-its-about-time-ce23581845ca\n",
    "- Could do this to encode the time series with the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad124f0a",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "> Should also try gradient boosting these\n",
    " - Decision trees tend to overfit on data with a large number of features. Getting the right ratio of samples to number of features is important, since a tree with few samples in high dimensional space is very likely to overfit.\n",
    " - Visualize your tree as you are training by using the export function. Use max_depth=3 as an initial tree depth to get a feel for how the tree is fitting to your data, and then increase the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a045f99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[263.   0.   0.   0.   0.   0.   0.   0. 343.]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 100.0\n",
      "CV r2: 91.234\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(tree.DecisionTreeRegressor(), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['Decision Tree', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5c771",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca1c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[165.69   0.     2.63   2.63   0.     2.63  26.87   0.   209.23]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 98.811\n",
      "CV r2: 75.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(RandomForestRegressor(), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['Random Forest', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72d965",
   "metadata": {},
   "source": [
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e38e62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+01, tolerance: 1.344e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[189.41106432  39.30311392 -29.21973662 -39.7150246    2.31680865\n",
      "  56.89921228   7.65530674  40.33453252 330.24990054]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 90.025\n",
      "CV r2: 74.649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(LassoCV(), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['LASSO', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52479020",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53b19cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 1.57238220e+02 -8.64173737e-02 -1.34849230e+02 -1.12424122e+02\n",
      "  9.51100877e+00  4.56509076e+01  5.17893558e+01  5.39806590e+01\n",
      "  4.57121688e+02]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 92.428\n",
      "CV r2: 24.127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(RidgeCV(), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['Ridge', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949beeb6",
   "metadata": {},
   "source": [
    "## SVR\n",
    " - Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the same scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e09d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 52.94606023   0.90020756 -95.41335448 -86.40411877  23.42422025\n",
      "  94.18366493 100.37955196  45.36313576  48.6996985 ]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 84.286\n",
      "CV r2: -15.18\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\n",
    "# Can vary kernel types, degrees, a few other boolean heuristics\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(SVR(kernel='linear'), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['Unscaled SVR (linear)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f663028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "scalery = StandardScaler().fit(np.reshape(y_train, (y_train.shape[0], 1)))\n",
    "\n",
    "X_train_sc = scalerX.transform(X_train)\n",
    "y_train_sc = scalery.transform(np.reshape(y_train, (y_train.shape[0], 1)))\n",
    "# You should test on these if you decide to actually use the SVR\n",
    "#X_test_sc = scalerX.transform(X_test)\n",
    "#y_test_sc = scalery.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51b00ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 0.69086738 -0.42527674 -1.87421785 -1.83010982 -0.40407303 -0.22367892\n",
      " -0.14098333  0.11003281  2.97719343]\n",
      "Ground Truth:\n",
      "[[ 2.16425416]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [ 1.53617556]]\n",
      "One Off r2: 99.079\n",
      "CV r2: 6.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(SVR(kernel='linear'), X_train_sc, y_train_sc, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['FSS SVR (linear)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7565a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 0.41395588 -0.42643273 -1.25263043 -1.28864147 -0.7071389  -0.29333612\n",
      " -0.04786832 -0.16086794  1.75929619]\n",
      "Ground Truth:\n",
      "[[ 2.16425416]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [ 1.53617556]]\n",
      "One Off r2: 95.898\n",
      "CV r2: 48.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(SVR(kernel='poly'), X_train_sc, y_train_sc, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['FSS SVR (poly)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71199e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 0.69623268 -0.40425281 -0.18966634 -0.13150945 -0.38552221 -0.42646935\n",
      " -0.34297474 -0.51585645  0.67229256]\n",
      "Ground Truth:\n",
      "[[ 2.16425416]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [ 1.53617556]]\n",
      "One Off r2: 94.761\n",
      "CV r2: 63.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(SVR(kernel='rbf'), X_train_sc, y_train_sc, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['FSS SVR (rbf)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3059514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[-0.20078109 -0.44216638 -0.7355274  -0.65939965 -0.56527481  0.42629398\n",
      "  0.50357112 -0.32957987 -0.26134627]\n",
      "Ground Truth:\n",
      "[[ 2.16425416]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [-0.52863282]\n",
      " [ 1.53617556]]\n",
      "One Off r2: 31.083\n",
      "CV r2: -21.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(SVR(kernel='sigmoid'), X_train_sc, y_train_sc, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['FSS SVR (sigmoid)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30db76",
   "metadata": {},
   "source": [
    "## Gaussian Process Regressor\n",
    "> I don't know how to use this one correctly, I didn't look that deeply into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f8f2791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012929610405862935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html\n",
    "\n",
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "#X, y = make_friedman2(n_samples=500, noise=0, random_state=0)\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, random_state=0).fit(X_train, y_train)\n",
    "# Shouldn't really be scoring on the data I trained it on...\n",
    "gpr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13103633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([49.79565028, 46.78400878, 43.65310835, 44.10141124, 44.4043447 ,\n",
       "        46.81960032, 46.66903181, 44.93356619, 49.79516335]),\n",
       " array([139.07785286, 139.2921885 , 140.75652042, 140.80310036,\n",
       "        140.43893816, 139.22380547, 139.18946045, 140.07678632,\n",
       "        139.08915183]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr.predict(X_train, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f568cd",
   "metadata": {},
   "source": [
    "## KNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d520485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[263.   0.   0.   0.   0.   0.   0.   0. 343.]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 100.0\n",
      "CV r2: 91.234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(KNeighborsRegressor(n_neighbors=1), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['K-Nearest Regression (1)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5180014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[131.5   0.    0.    0.    0.    0.    0.    0.  171.5]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 97.808\n",
      "CV r2: 63.631\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(KNeighborsRegressor(n_neighbors=2), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['K-Nearest Regression (2)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f52af71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[ 87.66666667   0.           0.           0.           0.\n",
      "   0.           0.           0.         114.33333333]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 83.836\n",
      "CV r2: 40.213\n"
     ]
    }
   ],
   "source": [
    "train_pred, r2, r2_cv = fit_ml_algo(KNeighborsRegressor(n_neighbors=3), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([['K-Nearest Regression (3)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "464a5d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions:\n",
      "[37.57142857 37.57142857 86.57142857 86.57142857 86.57142857 86.57142857\n",
      " 86.57142857 86.57142857 49.        ]\n",
      "Ground Truth:\n",
      "[343.   0.   0.   0.   0.   0.   0.   0. 263.]\n",
      "One Off r2: 23.383\n",
      "CV r2: -27.017\n"
     ]
    }
   ],
   "source": [
    "max_neighbors = 7 #X_train.shape[0] #--> CV only has 7 max for some reason\n",
    "#^ Not sure if above issue still exists or what the original cause was\n",
    "\n",
    "train_pred, r2, r2_cv = fit_ml_algo(KNeighborsRegressor(n_neighbors=max_neighbors), X_train, y_train, cv, verbose=True)\n",
    "temp_df = pd.DataFrame([[f'K-Nearest Regressor ({max_neighbors})', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "res_df = pd.concat((res_df, temp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b3c9f",
   "metadata": {},
   "source": [
    "# R2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd842944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>CV r2</th>\n",
       "      <th>K Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>91.234</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>75.980</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>74.649</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unscaled SVR (linear)</td>\n",
       "      <td>-15.180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FSS SVR (linear)</td>\n",
       "      <td>6.342</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FSS SVR (poly)</td>\n",
       "      <td>48.009</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FSS SVR (rbf)</td>\n",
       "      <td>63.833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FSS SVR (sigmoid)</td>\n",
       "      <td>-21.224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K-Nearest Regression (1)</td>\n",
       "      <td>91.234</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Nearest Regression (2)</td>\n",
       "      <td>63.631</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-Nearest Regression (3)</td>\n",
       "      <td>40.213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Nearest Regressor (7)</td>\n",
       "      <td>-27.017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Algorithm   CV r2 K Folds\n",
       "0              Decision Tree  91.234       5\n",
       "1              Random Forest  75.980       5\n",
       "2                      LASSO  74.649       5\n",
       "3                      Ridge  24.127       5\n",
       "4      Unscaled SVR (linear) -15.180       5\n",
       "5           FSS SVR (linear)   6.342       5\n",
       "6             FSS SVR (poly)  48.009       5\n",
       "7              FSS SVR (rbf)  63.833       5\n",
       "8          FSS SVR (sigmoid) -21.224       5\n",
       "9   K-Nearest Regression (1)  91.234       5\n",
       "10  K-Nearest Regression (2)  63.631       5\n",
       "11  K-Nearest Regression (3)  40.213       5\n",
       "12   K-Nearest Regressor (7) -27.017       5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.reset_index(inplace=True, drop=True)\n",
    "res_df.drop('One Off r2', axis=1, inplace=True)\n",
    "res_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d8f9393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION: 5 FOLDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>CV r2</th>\n",
       "      <th>K Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>91.234</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>75.980</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>74.649</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unscaled SVR (linear)</td>\n",
       "      <td>-15.180</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FSS SVR (linear)</td>\n",
       "      <td>6.342</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FSS SVR (poly)</td>\n",
       "      <td>48.009</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FSS SVR (rbf)</td>\n",
       "      <td>63.833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FSS SVR (sigmoid)</td>\n",
       "      <td>-21.224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K-Nearest Regression (1)</td>\n",
       "      <td>91.234</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Nearest Regression (2)</td>\n",
       "      <td>63.631</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-Nearest Regression (3)</td>\n",
       "      <td>40.213</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Nearest Regressor (7)</td>\n",
       "      <td>-27.017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Algorithm   CV r2 K Folds\n",
       "0              Decision Tree  91.234       5\n",
       "1              Random Forest  75.980       5\n",
       "2                      LASSO  74.649       5\n",
       "3                      Ridge  24.127       5\n",
       "4      Unscaled SVR (linear) -15.180       5\n",
       "5           FSS SVR (linear)   6.342       5\n",
       "6             FSS SVR (poly)  48.009       5\n",
       "7              FSS SVR (rbf)  63.833       5\n",
       "8          FSS SVR (sigmoid) -21.224       5\n",
       "9   K-Nearest Regression (1)  91.234       5\n",
       "10  K-Nearest Regression (2)  63.631       5\n",
       "11  K-Nearest Regression (3)  40.213       5\n",
       "12   K-Nearest Regressor (7) -27.017       5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"CROSS VALIDATION: 5 FOLDS\")\n",
    "res_df.loc[res_df['K Folds']==5].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff541f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED CROSS VALIDATION: 5 FOLDS\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>CV r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>91.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Regression (1)</td>\n",
       "      <td>91.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>75.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>74.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FSS SVR (rbf)</td>\n",
       "      <td>63.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Regression (2)</td>\n",
       "      <td>63.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FSS SVR (poly)</td>\n",
       "      <td>48.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Regression (3)</td>\n",
       "      <td>40.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>24.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FSS SVR (linear)</td>\n",
       "      <td>6.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Unscaled SVR (linear)</td>\n",
       "      <td>-15.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FSS SVR (sigmoid)</td>\n",
       "      <td>-21.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Nearest Regressor (7)</td>\n",
       "      <td>-27.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Algorithm   CV r2\n",
       "0              Decision Tree  91.234\n",
       "1   K-Nearest Regression (1)  91.234\n",
       "2              Random Forest  75.980\n",
       "3                      LASSO  74.649\n",
       "4              FSS SVR (rbf)  63.833\n",
       "5   K-Nearest Regression (2)  63.631\n",
       "6             FSS SVR (poly)  48.009\n",
       "7   K-Nearest Regression (3)  40.213\n",
       "8                      Ridge  24.127\n",
       "9           FSS SVR (linear)   6.342\n",
       "10     Unscaled SVR (linear) -15.180\n",
       "11         FSS SVR (sigmoid) -21.224\n",
       "12   K-Nearest Regressor (7) -27.017"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_res_df = res_df.sort_values(by=['CV r2'], ascending=False)\n",
    "print(\"SORTED CROSS VALIDATION: 5 FOLDS\")\n",
    "sorted_res_df5 = sorted_res_df.loc[sorted_res_df['K Folds']==5]\n",
    "sorted_res_df5_dropped = sorted_res_df5[['Algorithm', 'CV r2']]\n",
    "sorted_res_df5_dropped.reset_index(drop=True, inplace=True)\n",
    "sorted_res_df5_dropped.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e190d2",
   "metadata": {},
   "source": [
    "# Testing on testing dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42cb4647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "cv = 5\n",
    "num_decimals = 3\n",
    "test_df = pd.DataFrame(columns=my_metrics_cols)\n",
    "#my_metrics_cols = ['Algorithm', 'One Off r2', 'CV r2', 'K Folds']\n",
    "#res_df = pd.DataFrame(columns=my_metrics_cols)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "train_pred, r2, r2_cv, model = fit_ml_algo(tree.DecisionTreeRegressor(), X_train, y_train, cv, testing=True)\n",
    "# IS THIS WHAT I USE HERE TO TEST???\n",
    "#train_pred = model_selection.cross_val_predict(algo, \n",
    "#                                                  X_train, \n",
    "#                                                  y_train, \n",
    "#                                                  cv=cv, \n",
    "#                                                  n_jobs=-1)\n",
    "#    #mse_cv = round(metrics.mean_squared_error(y_train, train_pred) * 100, num_decimals)\n",
    "#    r2_cv = round(metrics.r2_score(y_train, train_pred) * 100, num_decimals)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['Decision Tree', 'NA', r2_cv, 'NA']], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b57750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>One Off r2</th>\n",
       "      <th>CV r2</th>\n",
       "      <th>K Folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>NA</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm One Off r2  CV r2 K Folds\n",
       "0  Decision Tree         NA  100.0      NA"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff160e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "100.0\n",
      "Random Forest\n",
      "98.83\n",
      "Ridge\n",
      "62.354\n",
      "LASSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmen\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+01, tolerance: 1.344e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.648\n",
      "K-Nearest Regression (1)\n",
      "100.0\n",
      "K-Nearest Regression (2)\n",
      "97.109\n"
     ]
    }
   ],
   "source": [
    "# Still using a cv of 5, as set way earlier\n",
    "r2 = 'NA'\n",
    "num_decimals = 3\n",
    "test_df = pd.DataFrame(columns=my_metrics_cols)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "_, _, r2_cv, my_dt = fit_ml_algo(tree.DecisionTreeRegressor(), X_train, y_train, cv, testing=True)\n",
    "y_pred = my_dt.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['Decision Tree', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))\n",
    "\n",
    "print(\"Random Forest\")\n",
    "_, _, r2_cv, model = fit_ml_algo(RandomForestRegressor(), X_train, y_train, cv, testing=True)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['Random Forest', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))\n",
    "\n",
    "print(\"Ridge\")\n",
    "_, _, r2_cv, model = fit_ml_algo(RidgeCV(), X_train, y_train, cv, testing=True)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['Ridge', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))\n",
    "\n",
    "print(\"LASSO\")\n",
    "_, _, r2_cv, model = fit_ml_algo(LassoCV(), X_train, y_train, cv, testing=True)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['LASSO', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))\n",
    "\n",
    "print(\"K-Nearest Regression (1)\")\n",
    "_, _, r2_cv, model = fit_ml_algo(KNeighborsRegressor(n_neighbors=1), X_train, y_train, cv, testing=True)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['K-Nearest Regression (1)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))\n",
    "\n",
    "print(\"K-Nearest Regression (2)\")\n",
    "_, _, r2_cv, model = fit_ml_algo(KNeighborsRegressor(n_neighbors=2), X_train, y_train, cv, testing=True)\n",
    "y_pred = model.predict(X_test)\n",
    "r2_cv = round(metrics.r2_score(y_test, y_pred) * 100, num_decimals)\n",
    "print(r2_cv)\n",
    "temp_df = pd.DataFrame([['K-Nearest Regression (2)', r2, r2_cv, cv]], columns=my_metrics_cols)\n",
    "test_df = pd.concat((test_df, temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7656daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED TEST SCORES:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>CV r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Regression (1)</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>98.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Regression (2)</td>\n",
       "      <td>97.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LASSO</td>\n",
       "      <td>77.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>62.354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Algorithm    CV r2\n",
       "0             Decision Tree  100.000\n",
       "1  K-Nearest Regression (1)  100.000\n",
       "2             Random Forest   98.830\n",
       "3  K-Nearest Regression (2)   97.109\n",
       "4                     LASSO   77.648\n",
       "5                     Ridge   62.354"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_test_df = test_df.sort_values(by=['CV r2'], ascending=False)\n",
    "print(\"SORTED TEST SCORES:\")\n",
    "sorted_test_df_dropped = sorted_test_df[['Algorithm', 'CV r2']]\n",
    "sorted_test_df_dropped.reset_index(drop=True, inplace=True)\n",
    "sorted_test_df_dropped.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f2f9c",
   "metadata": {},
   "source": [
    "I don't think CV is accurate anymore.  I believe it was only validated (e.g. not updated upon) using the CV results, so whether or not you use CV shouldn't affect the testing score (given you made the same selections/changes to the model).  CV should only be related to performance while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d24b0e",
   "metadata": {},
   "source": [
    "## Visualize Decision Tree for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5db360bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.6, 0.8333333333333334, 'X[1514] <= 0.563\\nsquared_error = 16223.778\\nsamples = 9\\nvalue = 67.333'),\n",
       " Text(0.4, 0.5, 'X[2944] <= 0.363\\nsquared_error = 1600.0\\nsamples = 2\\nvalue = 303.0'),\n",
       " Text(0.2, 0.16666666666666666, 'squared_error = 0.0\\nsamples = 1\\nvalue = 343.0'),\n",
       " Text(0.6, 0.16666666666666666, 'squared_error = 0.0\\nsamples = 1\\nvalue = 263.0'),\n",
       " Text(0.8, 0.5, 'squared_error = 0.0\\nsamples = 7\\nvalue = 0.0')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree.plot_tree(my_dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
